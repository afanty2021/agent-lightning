# 安装与配置

<cite>
**本文档中引用的文件**  
- [README.md](file://README.md)
- [pyproject.toml](file://pyproject.toml)
- [config.py](file://agentlightning/config.py)
- [verl/config.yaml](file://agentlightning/verl/config.yaml)
- [scripts/setup_stable.sh](file://scripts/setup_stable.sh)
- [scripts/setup_stable_gpu.sh](file://scripts/setup_stable_gpu.sh)
- [scripts/setup_latest.sh](file://scripts/setup_latest.sh)
- [scripts/setup_latest_gpu.sh](file://scripts/setup_latest_gpu.sh)
- [cli/__init__.py](file://agentlightning/cli/__init__.py)
- [cli/vllm.py](file://agentlightning/cli/vllm.py)
- [cli/store.py](file://agentlightning/cli/store.py)
- [cli/agentops_server.py](file://agentlightning/cli/agentops_server.py)
</cite>

## 目录
1. [简介](#简介)
2. [安装方法](#安装方法)
3. [依赖项管理](#依赖项管理)
4. [Python环境配置](#python环境配置)
5. [可选组件安装](#可选组件安装)
6. [配置文件结构](#配置文件结构)
7. [CLI工具配置](#cli工具配置)
8. [环境变量设置](#环境变量设置)
9. [多操作系统配置](#多操作系统配置)
10. [常见配置错误排查](#常见配置错误排查)

## 简介

Agent Lightning 是一个用于训练AI代理的框架，支持多种代理框架和算法。本文档详细介绍了在不同环境下的安装与配置方法，包括CPU/GPU、稳定版/最新版的安装，以及配置文件的结构和参数说明。

## 安装方法

### 基础安装

通过pip安装Agent Lightning：

```bash
pip install agentlightning
```

### 不同环境下的安装

#### 稳定版（CPU）

使用`setup_stable.sh`脚本进行安装：

```bash
./scripts/setup_stable.sh
```

该脚本会升级pip并安装项目及其开发、代理和APO依赖项。

#### 稳定版（GPU）

使用`setup_stable_gpu.sh`脚本进行安装：

```bash
./scripts/setup_stable_gpu.sh
```

该脚本会安装特定版本的PyTorch、vLLM、VERL等GPU相关依赖项。

#### 最新版（CPU）

使用`setup_latest.sh`脚本进行安装：

```bash
./scripts/setup_latest.sh
```

该脚本除了基础安装外，还会升级agentops到最新版本。

#### 最新版（GPU）

使用`setup_latest_gpu.sh`脚本进行安装：

```bash
./scripts/setup_latest_gpu.sh
```

该脚本会安装最新版本的PyTorch、vLLM和VERL，并安装TRL和Unsloth等可选组件。

**Section sources**
- [scripts/setup_stable.sh](file://scripts/setup_stable.sh)
- [scripts/setup_stable_gpu.sh](file://scripts/setup_stable_gpu.sh)
- [scripts/setup_latest.sh](file://scripts/setup_latest.sh)
- [scripts/setup_latest_gpu.sh](file://scripts/setup_latest_gpu.sh)

## 依赖项管理

### 核心依赖项

在`pyproject.toml`中定义了核心依赖项：

```toml
dependencies = [
  "graphviz",
  "psutil",
  "setproctitle",
  "flask",
  "agentops>=0.4.13",
  "httpdbg",
  "uvicorn",
  "fastapi",
  "aiohttp",
  "opentelemetry-api>=1.35",
  "opentelemetry-sdk>=1.35",
  "opentelemetry-exporter-otlp>=1.35",
  "litellm[proxy]>=1.74",
  "pydantic>=2.11",
  "openai",
  "rich",
]
```

### 可选依赖项

#### APO
```toml
apo = [
  "poml",
]
```

#### VERL
```toml
verl = [
  "verl>=0.5.0,<0.6.0",
  "vllm>=0.8.4,<0.11.0",
]
```

### 环境依赖组

#### 稳定版核心
```toml
core-stable = [
  "agentops>=0.4.21",
  "openai>=2.0.0",
]
```

#### 旧版核心
```toml
core-legacy = [
  "agentops<=0.4.18",
  "openai<2.0.0",
]
```

#### PyTorch CPU
```toml
torch-cpu = [
  "torch",
  "torchvision",
]
```

#### PyTorch GPU (CUDA 12.8)
```toml
torch-cu128 = [
  "torch",
  "torchvision",
]
```

#### 稳定版训练
```toml
torch-stable = [
  {include-group = "core-stable"},
  "torch>=2.8.0",
  "torchvision>=0.23.0",
  "transformers>=4.55.0",
  "vllm>=0.10.2",
  "litellm[proxy]>=1.78",
]
```

#### 旧版训练
```toml
torch-legacy = [
  {include-group = "core-legacy"},
  "torch==2.7.0",
  "torchvision==0.22.0",
  "transformers==4.53.3",
  "tokenizers>=0.21,<0.22",
  "flash-attn==2.8.1",
  "vllm==0.9.2",
  "litellm[proxy]==1.74.15",
]
```

#### GPU稳定版
```toml
torch-gpu-stable = [
  {include-group = "torch-stable"},
  {include-group = "torch-cu128"},
  "flash-attn>=2.8.3",
  "tensordict>=0.9.1",
]
```

#### GPU旧版
```toml
torch-gpu-legacy = [
  {include-group = "torch-legacy"},
  {include-group = "torch-cu128"},
  "flash-attn==2.8.1",
]
```

#### TRL/Unsloth
```toml
trl = [
  {include-group = "torch-stable"},
  "unsloth>=2025.10.1,!=2025.10.2,!=2025.10.3,!=2025.10.4,!=2025.10.5,!=2025.10.6,!=2025.10.7,!=2025.10.8",
  "unsloth_zoo>=2025.10.1,!=2025.10.2,!=2025.10.3,!=2025.10.4,!=2025.10.5,!=2025.10.6,!=2025.10.7,!=2025.10.8",
  "bitsandbytes",
  "peft",
  "datasets",
  "transformers",
  "trl",
  "kernels",
  "vllm",
]
```

#### Tinker
```toml
tinker = [
  {include-group = "torch-stable"},
  "tinker>=0.2.2",
  "tinker_cookbook",
  "wandb",
]
```

#### 代理框架
```toml
agents = [
  {include-group = "autogen"},
  {include-group = "openai-agents"},
  {include-group = "langchain"},
  {include-group = "sql"},
  {include-group = "anthropic"},
  {include-group = "crewai"},
]
```

**Section sources**
- [pyproject.toml](file://pyproject.toml)

## Python环境配置

### Python版本要求

项目要求Python 3.10或更高版本：

```toml
requires-python = ">=3.10"
```

### 虚拟环境建议

建议使用虚拟环境进行安装，以避免依赖冲突：

```bash
python -m venv agent-lightning-env
source agent-lightning-env/bin/activate  # Linux/macOS
# 或
agent-lightning-env\Scripts\activate  # Windows
```

### 类型检查环境

项目包含pyright配置文件，用于类型检查：

```json
{
  "include": ["agentlightning", "tests", "examples"],
  "exclude": ["**/data", "**/assets"],
  "pythonVersion": "3.12",
  "typeCheckingMode": "strict",
  "reportMissingTypeStubs": "none",
  "reportUnknownMemberType": "error",
  "reportUnknownVariableType": "error",
  "reportMissingImports": "error",
  "reportMissingModuleSource": "error",
  "reportOptionalMemberAccess": "error"
}
```

**Section sources**
- [pyproject.toml](file://pyproject.toml)
- [pyrightconfig.json](file://pyrightconfig.json)

## 可选组件安装

### APO组件

安装APO相关组件：

```bash
pip install agentlightning[apo]
```

### VERL组件

安装VERL相关组件：

```bash
pip install agentlightning[verl]
```

### 代理框架组件

安装所有支持的代理框架：

```bash
pip install agentlightning[agents]
```

### TRL/Unsloth组件

安装TRL和Unsloth相关组件：

```bash
pip install agentlightning[trl]
```

### Tinker组件

安装Tinker相关组件：

```bash
pip install agentlightning[tinker]
```

### 开发组件

安装开发依赖项：

```bash
pip install agentlightning[dev]
```

**Section sources**
- [pyproject.toml](file://pyproject.toml)

## 配置文件结构

### 全局配置

#### CLI配置系统

`config.py`文件实现了基于argparse的CLI配置系统，支持从命令行参数实例化类：

```python
def lightning_cli(*classes: Type[CliConfigurable]) -> CliConfigurable | Tuple[CliConfigurable, ...]:
    """
    解析命令行参数以配置和实例化提供的CliConfigurable类。

    Args:
        *classes: 继承自CliConfigurable的一个或多个类。每个类的
                  __init__参数将作为命令行参数暴露。

    Returns:
        实例化对象的元组，按输入类的顺序对应。
    """
```

支持的参数类型包括：
- 基本类型（str, int, float, bool）
- 可选类型（Optional[T]）
- 列表类型（List[T]）
- 可选列表类型（Optional[List[T]]）

#### 类型转换函数

```python
def nullable_str(value: str) -> str | None:
    """将特定字符串值（不区分大小写）转换为None，否则返回字符串。"""
    if value.lower() in ["none", "null", "~", "nil"]:
        return None
    return value

def nullable_int(value: str) -> int | None:
    """将特定字符串值（不区分大小写）转换为None，否则返回整数。"""
    if value.lower() in ["none", "null", "~", "nil"]:
        return None
    try:
        return int(value)
    except ValueError:
        raise argparse.ArgumentTypeError(f"无效的整数值: '{value}'")

def nullable_float(value: str) -> float | None:
    """将特定字符串值（不区分大小写）转换为None，否则返回浮点数。"""
    if value.lower() in ["none", "null", "~", "nil"]:
        return None
    try:
        return float(value)
    except ValueError:
        raise argparse.ArgumentTypeError(f"无效的浮点数值: '{value}'")

def _str_to_bool(v: str) -> bool:
    """将常见的布尔字符串表示转换为Python布尔值（不区分大小写）。"""
    if isinstance(v, bool):
        return v
    lowered_v = v.lower()
    if lowered_v in ("yes", "true", "t", "y", "1"):
        return True
    elif lowered_v in ("no", "false", "f", "n", "0"):
        return False
    else:
        raise argparse.ArgumentTypeError(f"期望布尔值（例如 'true', 'false', 'yes', 'no'），得到 '{v}'")
```

### VERL专用配置

`verl/config.yaml`文件定义了VERL训练的配置：

```yaml
hydra:
  searchpath:
    - pkg://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

agentlightning:
  port: 9999

data:
  filter_overlong_prompts: false

actor_rollout_ref:
  rollout:
    mode: async
    agent:
      custom_async_server:
        path: pkg://agentlightning.verl.async_server
        name: PatchedvLLMServer
```

#### 配置参数说明

| 参数 | 说明 | 取值范围 | 最佳实践 |
|------|------|---------|---------|
| `hydra.searchpath` | Hydra配置搜索路径 | pkg://verl/trainer/config | 保持默认值 |
| `defaults` | 默认配置 | ppo_trainer, _self_ | 保持默认值 |
| `agentlightning.port` | Agent Lightning端口 | 1024-65535 | 建议使用9999 |
| `data.filter_overlong_prompts` | 是否过滤过长的提示 | true, false | 根据数据集调整 |
| `actor_rollout_ref.rollout.mode` | 回滚模式 | async, sync | 建议使用async |
| `actor_rollout_ref.agent.custom_async_server.path` | 自定义异步服务器路径 | pkg://agentlightning.verl.async_server | 保持默认值 |
| `actor_rollout_ref.agent.custom_async_server.name` | 自定义异步服务器名称 | PatchedvLLMServer | 保持默认值 |

**Section sources**
- [agentlightning/config.py](file://agentlightning/config.py)
- [agentlightning/verl/config.yaml](file://agentlightning/verl/config.yaml)

## CLI工具配置

### CLI入口点

`cli/__init__.py`文件定义了CLI入口点和子命令：

```python
_SUBCOMMANDS: Dict[str, Tuple[str, str]] = {
    "vllm": ("agentlightning.cli.vllm", "Run the vLLM CLI with Agent Lightning instrumentation."),
    "store": ("agentlightning.cli.store", "Run a LightningStore server."),
    "agentops": ("agentlightning.cli.agentops_server", "Start the AgentOps server manager."),
}
```

### 子命令说明

#### vLLM子命令

`cli/vllm.py`文件实现了vLLM CLI的集成：

```python
def main(argv: Iterable[str] | None = None) -> int:
    from vllm.entrypoints.cli.main import main as vllm_main
    from agentlightning.instrumentation.vllm import instrument_vllm
    instrument_vllm()
    # ... 调用vLLM主函数
```

#### Store子命令

`cli/store.py`文件实现了LightningStore服务器：

```python
def main(argv: Iterable[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description="Run a LightningStore server")
    parser.add_argument("--port", type=int, default=4747, help="Port to run the server on")
    # ... 启动服务器
```

#### AgentOps子命令

`cli/agentops_server.py`文件实现了AgentOps服务器管理器：

```python
def main(argv: Iterable[str] | None = None) -> int:
    parser = argparse.ArgumentParser(description="Start AgentOps server")
    parser.add_argument("--daemon", action="store_true", help="Run server as a daemon")
    parser.add_argument("--port", type=int, default=8002, help="Port to run the server on")
    # ... 启动服务器管理器
```

### 使用方法

```bash
# 显示帮助信息
agl --help

# 运行vLLM CLI
agl vllm --help

# 运行LightningStore服务器
agl store --port 4747

# 启动AgentOps服务器
agl agentops --port 8002 --daemon
```

**Section sources**
- [agentlightning/cli/__init__.py](file://agentlightning/cli/__init__.py)
- [agentlightning/cli/vllm.py](file://agentlightning/cli/vllm.py)
- [agentlightning/cli/store.py](file://agentlightning/cli/store.py)
- [agentlightning/cli/agentops_server.py](file://agentlightning/cli/agentops_server.py)

## 环境变量设置

### AgentOps环境变量

在`tracer/agentops.py`中设置了AgentOps相关的环境变量：

```python
env_vars_to_set = {
    "AGENTOPS_API_KEY": "dummy",
    "AGENTOPS_API_ENDPOINT": base_url,
    "AGENTOPS_APP_URL": f"{base_url}/notavailable",
    "AGENTOPS_EXPORTER_ENDPOINT": f"{base_url}/traces",
}
```

### Ray运行时环境变量

在`verl/entrypoint.py`中设置了Ray运行时环境变量：

```python
ray.init(
    runtime_env={
        "env_vars": {"TOKENIZERS_PARALLELISM": "true", "NCCL_DEBUG": "WARN", "VLLM_LOGGING_LEVEL": "WARN"}
    },
    num_cpus=config.ray_init.num_cpus,
)
```

### 推荐的环境变量

| 环境变量 | 说明 | 推荐值 | 作用范围 |
|---------|------|-------|---------|
| `TOKENIZERS_PARALLELISM` | 控制分词器并行化 | true | 所有使用Hugging Face分词器的组件 |
| `NCCL_DEBUG` | NCCL调试级别 | WARN | 分布式训练 |
| `VLLM_LOGGING_LEVEL` | vLLM日志级别 | WARN | vLLM相关组件 |
| `AGENTOPS_API_KEY` | AgentOps API密钥 | dummy（本地） | AgentOps集成 |
| `AGENTOPS_API_ENDPOINT` | AgentOps API端点 | http://localhost:8002 | AgentOps集成 |
| `AGENTOPS_APP_URL` | AgentOps应用URL | http://localhost:8002/notavailable | AgentOps集成 |
| `AGENTOPS_EXPORTER_ENDPOINT` | AgentOps导出端点 | http://localhost:8002/traces | AgentOps集成 |

**Section sources**
- [agentlightning/tracer/agentops.py](file://agentlightning/tracer/agentops.py)
- [agentlightning/verl/entrypoint.py](file://agentlightning/verl/entrypoint.py)

## 多操作系统配置

### Linux配置

Linux系统通常不需要特殊配置，但建议：

1. 确保CUDA驱动已正确安装（GPU版本）
2. 设置适当的文件描述符限制
3. 配置共享内存大小

```bash
# 增加共享内存大小
sudo sysctl -w kernel.shmmax=128000000000
sudo sysctl -w kernel.shmall=32000000000
```

### macOS配置

macOS系统需要注意：

1. Apple Silicon (M1/M2)芯片使用不同的PyTorch构建
2. 可能需要安装Xcode命令行工具
3. 某些依赖项可能需要通过conda安装

```bash
# 安装Xcode命令行工具
xcode-select --install

# 对于Apple Silicon，使用conda安装PyTorch
conda install pytorch torchvision torchaudio -c pytorch
```

### Windows配置

Windows系统需要特别注意：

1. 确保Visual Studio Build Tools已安装
2. 可能需要设置长路径支持
3. 某些依赖项可能需要预编译的wheel文件

```cmd
:: 安装Visual Studio Build Tools
:: 从https://visualstudio.microsoft.com/visual-cpp-build-tools/下载

:: 启用长路径支持（Windows 10 1607+）
reg add "HKLM\SYSTEM\CurrentControlSet\Control\FileSystem" /v LongPathsEnabled /t REG_DWORD /d 1
```

### 跨平台注意事项

1. 路径分隔符：使用`os.path.join()`或`pathlib`处理路径
2. 行结束符：确保文本文件使用适当的行结束符
3. 文件权限：注意不同操作系统的文件权限模型
4. 环境变量：使用`os.environ`访问环境变量，确保跨平台兼容性

**Section sources**
- [agentlightning/verl/entrypoint.py](file://agentlightning/verl/entrypoint.py)
- [agentlightning/tracer/agentops.py](file://agentlightning/tracer/agentops.py)

## 常见配置错误排查

### 依赖项冲突

**问题**：安装时出现依赖项冲突

**解决方案**：
1. 使用虚拟环境隔离依赖项
2. 检查`pyproject.toml`中的冲突组：
   ```toml
   conflicts = [
     [
       { group = "core-legacy" },
       { group = "core-stable" },
     ],
     [
       { group = "torch-cpu" },
       { group = "torch-cu128" },
     ],
     [
       { group = "torch-stable" },
       { group = "torch-legacy" },
     ],
   ]
   ```
3. 避免同时安装冲突的依赖组

### 端口冲突

**问题**：服务启动时端口被占用

**解决方案**：
1. 检查端口使用情况：
   ```bash
   # Linux/macOS
   lsof -i :9999
   # Windows
   netstat -ano | findstr :9999
   ```
2. 修改配置文件中的端口：
   ```yaml
   agentlightning:
     port: 9999  # 修改为未使用的端口
   ```
3. 或通过命令行参数指定端口：
   ```bash
   agl store --port 4748
   ```

### CUDA/GPU问题

**问题**：GPU版本无法使用CUDA

**解决方案**：
1. 检查CUDA驱动版本：
   ```bash
   nvidia-smi
   ```
2. 确保PyTorch CUDA版本匹配：
   ```python
   import torch
   print(torch.cuda.is_available())
   print(torch.version.cuda)
   ```
3. 检查vLLM CUDA支持：
   ```python
   from vllm import LLM
   llm = LLM(model="Qwen/Qwen2.5-1.5B-Instruct", tensor_parallel_size=1)
   ```

### 配置解析错误

**问题**：CLI配置解析失败

**解决方案**：
1. 检查参数名称格式：
   ```bash
   # 正确格式：--类名.参数名
   agl vllm --llmproxy.model Qwen/Qwen2.5-1.5B-Instruct
   ```
2. 检查参数类型：
   - 布尔值：使用`true`/`false`或`yes`/`no`
   - 可选值：使用`none`、`null`、`~`或`nil`表示None
   - 列表：直接提供多个值
3. 查看详细的帮助信息：
   ```bash
   agl vllm --help
   ```

### Ray初始化问题

**问题**：Ray集群初始化失败

**解决方案**：
1. 检查Ray是否已正确安装
2. 确保有足够的CPU资源
3. 检查网络配置：
   ```python
   ray.init(
       runtime_env={
           "env_vars": {"TOKENIZERS_PARALLELISM": "true", "NCCL_DEBUG": "WARN", "VLLM_LOGGING_LEVEL": "WARN"}
       },
       num_cpus=config.ray_init.num_cpus,
   )
   ```

### 环境变量未生效

**问题**：环境变量设置后未生效

**解决方案**：
1. 确保在正确的作用域内设置环境变量
2. 检查变量名称拼写
3. 在代码中验证环境变量：
   ```python
   import os
   print(os.environ.get("AGENTOPS_API_ENDPOINT"))
   ```
4. 确保在进程启动前设置环境变量

**Section sources**
- [pyproject.toml](file://pyproject.toml)
- [agentlightning/verl/config.yaml](file://agentlightning/verl/config.yaml)
- [agentlightning/config.py](file://agentlightning/config.py)
- [agentlightning/verl/entrypoint.py](file://agentlightning/verl/entrypoint.py)
- [agentlightning/tracer/agentops.py](file://agentlightning/tracer/agentops.py)